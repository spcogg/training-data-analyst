{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets for the Content-based Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds the data we will use for creating our content based model. We'll collect the data via a collection of SQL queries from the publicly avialable Kurier.at dataset in BigQuery.\n",
    "Kurier.at is an Austrian newsite. The goal of these labs is to recommend an article for a visitor to the site. In this lab we collect the data for training. In the subsequent notebook we train the recommender model. \n",
    "\n",
    "This notebook illustrates\n",
    "* how to pull data from BigQuery table and write to local files\n",
    "* how to make reproducible train and test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import google.datalab.bigquery as bq\n",
    "\n",
    "PROJECT = 'qwiklabs-gcp-2737edcaba61fe20' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-2737edcaba61fe20' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud  config  set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this helper funciton to write lists containing article ids, categories, and authors for each article in our database to local file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_disk(my_list, filename):\n",
    "  with open(filename, 'w') as f:\n",
    "    for item in my_list:\n",
    "        line = \"%s\\n\" % item\n",
    "        f.write(str(line.encode('utf8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from BigQuery\n",
    "\n",
    "The cell below creates a local text file containing all the article ids (i.e. 'content ids') in the dataset. \n",
    "\n",
    "Have a look at the original dataset in [BigQuery](https://bigquery.cloud.google.com/welcome/). Then read through the query below and make sure you understand what it is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample content IDs ['299837992', '254619647', '299972800']\n",
      "The total number of articles is 15634\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY\n",
    "  content_id\n",
    "\"\"\"\n",
    "content_ids_list = bq.Query(sql).execute().result().to_dataframe()['content_id'].tolist()\n",
    "write_list_to_disk(content_ids_list, \"content_ids.txt\")\n",
    "print(\"Some sample content IDs {}\".format(content_ids_list[:3]))\n",
    "print(\"The total number of articles is {}\".format(len(content_ids_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT', 'PAGE', 'SOCIAL']\n"
     ]
    }
   ],
   "source": [
    "# try and figure out the different hit types\n",
    "# also check out this whole 'unnest' thing they've got going on with the data structure...\n",
    "# not sure how they've wierded up SQL\n",
    "sql=\"\"\"\n",
    "SELECT  distinct\n",
    "  hits.type as hit_type # figure out hit types \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "\"\"\"\n",
    "hit_types = bq.Query(sql).execute().result().to_dataframe()['hit_type'].tolist()\n",
    "print(hit_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, you will create a local file which contains a list of article categories and a list of article authors.\n",
    "\n",
    "**Hint**: For the TODO below, modify the query above changing 'content_id' to the necessary field and changing index=10 \n",
    "to the appropriate index.  \n",
    "Refer back to the original dataset, use the `hits.customDimensions.index` \n",
    "field to find the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stars & Kultur', 'News', 'Lifestyle']\n"
     ]
    }
   ],
   "source": [
    "#TODO: Modify the above query to instead create a list of all categories in the dataset.\n",
    "#You'll need to change the content_id to the appropriate field as well as the index. \n",
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  category\n",
    "\"\"\"\n",
    "categories_list = bq.Query(sql).execute().result().to_dataframe()['category'].tolist()\n",
    "#TODO: Modify the query above to create the list of categories\n",
    "write_list_to_disk(categories_list, \"categories.txt\")\n",
    "print(categories_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the author list, we'll only use the first author information for each article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample authors ['Christina Michlits', 'Mathias Kainz', 'Thomas  Trescher', 'Stefan Berndl', 'Anita Kattinger', 'Martina Salomon', 'Marlene Patsalidis', 'Georg Leyrer', 'Elisabeth Spitzer', 'Elisabeth Sereda']\n",
      "The total number of authors is 385\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  REGEXP_EXTRACT((SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)), r\"^[^,]+\")  AS first_author  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  first_author\n",
    "\"\"\"\n",
    "authors_list = bq.Query(sql).execute().result().to_dataframe()['first_author'].tolist()\n",
    "write_list_to_disk(authors_list, \"authors.txt\")\n",
    "print(\"Some sample authors {}\".format(authors_list[:10]))\n",
    "print(\"The total number of authors is {}\".format(len(authors_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets.\n",
    "\n",
    "In this section, we will create the train/test split of our data for training our model. Read through the query and complete the TODO at the bottom.  \n",
    "Use the concatenated values for visitor id and content id to create a farm fingerprint, taking 90% of the data for the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000196974485173657</td>\n",
       "      <td>299836841</td>\n",
       "      <td>News</td>\n",
       "      <td>ÖVP will Studiengebühren FPÖ in Verhandlungen ...</td>\n",
       "      <td>Raffaela Lindorfer</td>\n",
       "      <td>574</td>\n",
       "      <td>299959410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000196974485173657</td>\n",
       "      <td>299959410</td>\n",
       "      <td>News</td>\n",
       "      <td>Koalition: Bildungspapier mit mehr Pflichten u...</td>\n",
       "      <td>Peter Temel</td>\n",
       "      <td>574</td>\n",
       "      <td>299925086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000196974485173657</td>\n",
       "      <td>299925086</td>\n",
       "      <td>News</td>\n",
       "      <td>Marihuana-Adventkalender findet in Kanada reiß...</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299826775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000196974485173657</td>\n",
       "      <td>299826775</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Auf Bank ausgeruht: Pensionist muss Strafe zahlen</td>\n",
       "      <td>Marlene Patsalidis</td>\n",
       "      <td>574</td>\n",
       "      <td>299930679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000196974485173657</td>\n",
       "      <td>299930679</td>\n",
       "      <td>News</td>\n",
       "      <td>Wintereinbruch naht: Erster Schnee im Osten mö...</td>\n",
       "      <td>Daniela Wahl</td>\n",
       "      <td>574</td>\n",
       "      <td>299950903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitor_id content_id   category  \\\n",
       "0  1000196974485173657  299836841       News   \n",
       "1  1000196974485173657  299959410       News   \n",
       "2  1000196974485173657  299925086       News   \n",
       "3  1000196974485173657  299826775  Lifestyle   \n",
       "4  1000196974485173657  299930679       News   \n",
       "\n",
       "                                               title              author  \\\n",
       "0  ÖVP will Studiengebühren FPÖ in Verhandlungen ...  Raffaela Lindorfer   \n",
       "1  Koalition: Bildungspapier mit mehr Pflichten u...         Peter Temel   \n",
       "2  Marihuana-Adventkalender findet in Kanada reiß...                None   \n",
       "3  Auf Bank ausgeruht: Pensionist muss Strafe zahlen  Marlene Patsalidis   \n",
       "4  Wintereinbruch naht: Erster Schnee im Osten mö...        Daniela Wahl   \n",
       "\n",
       "   months_since_epoch next_content_id  \n",
       "0                 574       299959410  \n",
       "1                 574       299925086  \n",
       "2                 574       299826775  \n",
       "3                 574       299930679  \n",
       "4                 574       299950903  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "  --, ABS(FARM_FINGERPRINT(CONCAT(visitor_id, content_id))) as farm_id -- don't actually need this in the file\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL \n",
    "  AND MOD(ABS(FARM_FINGERPRINT(CONCAT(visitor_id, content_id))), 10) < 9 -- remember index starts at 0\n",
    "  --AND RAND() < 0.0005 -- if random sampling further required\n",
    "\"\"\"\n",
    "# TODO: Use FARM_FINGERPRINT on the concatenated visitor_id and content_id to create a training set of approximately 90% of the data\n",
    "# the hash output can't be used in the same pass\n",
    "training_set_df = bq.Query(sql).execute().result().to_dataframe()\n",
    "training_set_df.to_csv('training_set.csv', header=False, index=False, encoding='utf-8')\n",
    "training_set_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232308, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full size is 257907,8\n",
    "training_set_df.shape  # 90% should give ~232308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the query as above but change outcome of the farm fingerprint hash to collect the remaining 10% of the data for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025265994336570</td>\n",
       "      <td>299816215</td>\n",
       "      <td>News</td>\n",
       "      <td>Fahnenskandal von Mailand: Die Austria zeigt F...</td>\n",
       "      <td>Alexander Strecha</td>\n",
       "      <td>574</td>\n",
       "      <td>299954138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000163602560555666</td>\n",
       "      <td>299814775</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Meghan Markle: Verlobungsring aus Dianas Brosche</td>\n",
       "      <td>Maria Zelenko</td>\n",
       "      <td>574</td>\n",
       "      <td>299907204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000163602560555666</td>\n",
       "      <td>299972800</td>\n",
       "      <td>News</td>\n",
       "      <td>Strengere Regeln für Schüler Eltern – und auch...</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299824032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000163602560555666</td>\n",
       "      <td>299972800</td>\n",
       "      <td>News</td>\n",
       "      <td>Strengere Regeln für Schüler Eltern – und auch...</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299809748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000295479560700003</td>\n",
       "      <td>299836255</td>\n",
       "      <td>News</td>\n",
       "      <td>Blümel Kneissl &amp;Co.: Das sind die Fixstarter</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299833840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitor_id content_id   category  \\\n",
       "0  1000025265994336570  299816215       News   \n",
       "1  1000163602560555666  299814775  Lifestyle   \n",
       "2  1000163602560555666  299972800       News   \n",
       "3  1000163602560555666  299972800       News   \n",
       "4  1000295479560700003  299836255       News   \n",
       "\n",
       "                                               title             author  \\\n",
       "0  Fahnenskandal von Mailand: Die Austria zeigt F...  Alexander Strecha   \n",
       "1   Meghan Markle: Verlobungsring aus Dianas Brosche      Maria Zelenko   \n",
       "2  Strengere Regeln für Schüler Eltern – und auch...               None   \n",
       "3  Strengere Regeln für Schüler Eltern – und auch...               None   \n",
       "4       Blümel Kneissl &Co.: Das sind die Fixstarter               None   \n",
       "\n",
       "   months_since_epoch next_content_id  \n",
       "0                 574       299954138  \n",
       "1                 574       299907204  \n",
       "2                 574       299824032  \n",
       "3                 574       299809748  \n",
       "4                 574       299833840  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL\n",
    "--TODO: Modify the FARM_FINGERPRINT you used in the previous cell to create a test set of approximately 10% of the data\n",
    "  AND MOD(ABS(FARM_FINGERPRINT(CONCAT(visitor_id, content_id))), 10) = 9 -- remember index starts at 0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_set_df = bq.Query(sql).execute().result().to_dataframe()\n",
    "test_set_df.to_csv('test_set.csv', header=False, index=False, encoding='utf-8')\n",
    "test_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25599, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the two csv files we just created containing the training and test set. We'll also do a line count of both files to confirm that we have achieved an approximate 90/10 train/test split.  \n",
    "In the next notebook, **Content Based Filtering** we will build a model to recommend an article given information about the current article being read, such as the category, title, author, and publish date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25599 test_set.csv\n",
      "  232308 training_set.csv\n",
      "  257907 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> test_set.csv <==\r\n",
      "1000025265994336570,299816215,News,Fahnenskandal von Mailand: Die Austria zeigt Flagge,Alexander Strecha,574,299954138\r\n",
      "1000163602560555666,299814775,Lifestyle,Meghan Markle: Verlobungsring aus Dianas Brosche,Maria Zelenko,574,299907204\r\n",
      "1000163602560555666,299972800,News,Strengere Regeln für Schüler Eltern – und auch Lehrer,,574,299824032\r\n",
      "1000163602560555666,299972800,News,Strengere Regeln für Schüler Eltern – und auch Lehrer,,574,299809748\r\n",
      "1000295479560700003,299836255,News,Blümel Kneissl &Co.: Das sind die Fixstarter,,574,299833840\r\n",
      "1003281757411139142,299866366,News,\"Trump sorgt mit \"\"Pocahontas\"\"-Sager für Eklat\",Moritz Gottsauner-Wolf,574,299831571\r\n",
      "1004845194187735517,299866366,News,\"Trump sorgt mit \"\"Pocahontas\"\"-Sager für Eklat\",Moritz Gottsauner-Wolf,574,299816215\r\n",
      "1009895431438339410,293173038,,Heidi Strobl: Griessknödel mit karamellisierter Birne,Heidi Strobl,573,299816215\r\n",
      "10102541958680734,299816215,News,Fahnenskandal von Mailand: Die Austria zeigt Flagge,Alexander Strecha,574,299816215\r\n",
      "10102541958680734,299816215,News,Fahnenskandal von Mailand: Die Austria zeigt Flagge,Alexander Strecha,574,299799049\r\n",
      "\r\n",
      "==> training_set.csv <==\r\n",
      "1000196974485173657,299836841,News,\"ÖVP will Studiengebühren FPÖ in Verhandlungen \"\"flexibel\"\"\",Raffaela Lindorfer,574,299959410\r\n",
      "1000196974485173657,299959410,News,Koalition: Bildungspapier mit mehr Pflichten und Noten,Peter Temel,574,299925086\r\n",
      "1000196974485173657,299925086,News,Marihuana-Adventkalender findet in Kanada reißenden Absatz,,574,299826775\r\n",
      "1000196974485173657,299826775,Lifestyle,Auf Bank ausgeruht: Pensionist muss Strafe zahlen,Marlene Patsalidis,574,299930679\r\n",
      "1000196974485173657,299930679,News,Wintereinbruch naht: Erster Schnee im Osten möglich,Daniela Wahl,574,299950903\r\n",
      "1000196974485173657,299950903,News,Vienna: OGH bestätigt Zwangsabstieg in 2. Landesliga,Stefan Berndl,574,299965875\r\n",
      "1000196974485173657,299965875,News,Finanzinvestor fordert Ende der Fusionsgespräche CA Immo/Immofinanz,Irmgard Kischko,574,299925700\r\n",
      "1000196974485173657,299816215,News,Fahnenskandal von Mailand: Die Austria zeigt Flagge,Alexander Strecha,574,299930032\r\n",
      "1000196974485173657,299930032,News,Google steigt bei Wiener IT-Firma ein,Stefan Hofer,574,299826767\r\n",
      "1000196974485173657,299826767,Lifestyle,Titanic-Regisseur: Darum musste Jack sterben,Elisabeth Mittendorfer,574,299972194\r\n"
     ]
    }
   ],
   "source": [
    "!head *_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
