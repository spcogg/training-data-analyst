{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator.\n",
    "<hr/>\n",
    "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a5eb312004ba>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 28, 28, 1)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd71eabc6a0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd71e3a6f60>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd71e3a6da0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist # check what's in it, can see trian, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28, 1)\n",
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.validation.images.shape)\n",
    "print(mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configured as global variables...oook.\n",
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd71b840d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO=121\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(img):\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    This one needs to go from raw input image data, into a vector of the relative confidence \n",
    "    probailities of each classes, as well as the number of classes in the model\n",
    "    \n",
    "    Note this is a linear model, so even thought it output says ylogit, the values will be \n",
    "    any real number, because not converted into a logit\n",
    "    \"\"\"\n",
    "    X = tf.reshape(img, [-1, HEIGHT*WIDTH])  # flatten into 1D vector of [-1, H*W]\n",
    "    W = tf.Variable(tf.zeros([HEIGHT*WIDTH, NCLASSES])) # this is [HEIGHT*WIDTH, CLASSES]\n",
    "    b = tf.Variable(tf.zeros([NCLASSES])) # this is a scalar [NCLASSES]\n",
    "    ylogits = tf.matmul(X, W) + b # [-1, NCLASSES]  after the matrix multiply    \n",
    "    \n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.train.images},\n",
    "    y=mnist.train.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    #TODO\n",
    "    x={'image':mnist.validation.images},\n",
    "    y=mnist.validation.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "def serving_input_fn():\n",
    "    inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "    features = inputs # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Custom Estimator\n",
    "I could have simply used a canned LinearClassifier, but later on, I will want to use different models, and so let's write a custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  ylogits, nclasses = linear_model(features['image'])\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ylogits, labels=labels))\n",
    "    evalmetrics =  {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                                 learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    " \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=evalmetrics,\n",
    "        export_outputs={'classes': tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classes\": classes})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                     params = hparams,\n",
    "                                     model_dir = output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                    max_steps = hparams['train_steps'])\n",
    "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                  steps = None,\n",
    "                                  exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd71b749a90>, '_task_type': 'worker', '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_master': '', '_service': None, '_num_ps_replicas': 0, '_model_dir': 'mnist/learned', '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_train_distribute': None, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_is_chief': True, '_task_id': 0}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.3025854\n",
      "INFO:tensorflow:global_step/sec: 310.644\n",
      "INFO:tensorflow:step = 101, loss = 0.43405905 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.752\n",
      "INFO:tensorflow:step = 201, loss = 0.26429808 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.821\n",
      "INFO:tensorflow:step = 301, loss = 0.3326257 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.491\n",
      "INFO:tensorflow:step = 401, loss = 0.2904962 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.286\n",
      "INFO:tensorflow:step = 501, loss = 0.25115964 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.733\n",
      "INFO:tensorflow:step = 601, loss = 0.36478972 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.42\n",
      "INFO:tensorflow:step = 701, loss = 0.36140805 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.023\n",
      "INFO:tensorflow:step = 801, loss = 0.30274162 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.183\n",
      "INFO:tensorflow:step = 901, loss = 0.18118788 (0.262 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.307554.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-07-13:05:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-07-13:05:55\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9178, global_step = 1000, loss = 0.29481965\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classes']\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"mnist/learned/export/Servo/temp-b'1554642355'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "OUTDIR='mnist/learned'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {'train_steps': 1000, 'learning_rate': 0.01}\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What accuracy did you achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
